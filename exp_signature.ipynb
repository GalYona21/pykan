{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from kan import *\n",
    "from my_functions import calculate_signature, calculate_signature_over_all_surface, format_signature\n",
    "import fpsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0    951   8603 104519   9116 115547  11546  42974 114773 169557]\n"
     ]
    }
   ],
   "source": [
    "mesh_path = \"data/armadillo_curvs.ply\"\n",
    "mesh = trimesh.load(mesh_path)\n",
    "vertices = np.array(mesh.vertices)\n",
    "sampled_indices = fpsample.fps_sampling(vertices, 10, start_idx=0) # the start index is for reproducibility\n",
    "print(sampled_indices)\n",
    "# dataset_full_sample = create_dataset_from_mesh(mesh_path=mesh_path, sampled_index=0, show_sample=True, ball_radius=0.05, seed=0, down_sampling_ratio=1.0)\n",
    "# print(dataset_full_sample[\"train_input\"].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices: 172974\n",
      "dataset full size: 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.70e-02 | test loss: 1.79e-02 | reg: 3.10e+00 : 100%|██| 20/20 [00:02<00:00,  7.50it/s]\n",
      "train loss: 2.08e-03 | test loss: 3.06e-03 | reg: 4.14e+00 : 100%|██| 50/50 [00:02<00:00, 18.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 0.9870117902755737\n",
      "r2 is 0.9114292860031128\n",
      "r2 is 0.9171762466430664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 4.56e-03 | test loss: 5.70e-03 | reg: 1.05e+01 : 100%|██| 50/50 [00:00<00:00, 54.00it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265010.15*((0.08 - x_1)**4 + 0.14*(-x_2 - 0.07)**3)**2 - 0.01\n",
      "Number of vertices: 172974\n",
      "dataset down sampled size: 268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.87e-02 | test loss: 1.86e-02 | reg: 3.15e+00 : 100%|██| 20/20 [00:02<00:00,  9.83it/s]\n",
      "train loss: 4.58e-03 | test loss: 5.81e-03 | reg: 3.99e+00 : 100%|██| 50/50 [00:00<00:00, 62.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value at boundary.\n",
      "r2 is 0.9999983310699463\n",
      "r2 is 0.999999463558197\n",
      "r2 is 0.9999933242797852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 4.58e-03 | test loss: 5.81e-03 | reg: 1.01e+01 : 100%|██| 50/50 [00:00<00:00, 86.26it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336620.65*((0.08 - x_1)**4 + 0.14*(-x_2 - 0.06)**3)**2 - 0.01\n",
      "sampled_index 0 signature  tensor([[   -3.4162,   -40.4343,  -162.4794,    17.1123, -2196.4678,  -457.5745]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "sampled_index 0 signature  tensor([[   -3.3444,   -44.5783,  -169.9144,    16.8277, -2443.8635,  -524.4351]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "Number of vertices: 172974\n",
      "dataset full size: 337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.20e-02 | test loss: 1.93e-02 | reg: 3.31e+00 : 100%|██| 20/20 [00:02<00:00,  7.68it/s]\n",
      "train loss: 1.36e-02 | test loss: 3.31e+00 | reg: 1.63e+01 : 100%|██| 50/50 [00:01<00:00, 25.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 0.9821332097053528\n",
      "r2 is 0.9993422031402588\n",
      "r2 is 0.9437013268470764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.41e-02 | test loss: 3.56e-02 | reg: 1.24e+03 : 100%|██| 50/50 [00:01<00:00, 38.83it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.64*(-0.62*(0.14 - x_2)**3 + (0.21 - x_1)**4 + 0.24)**2 - 1.45\n",
      "Number of vertices: 172974\n",
      "dataset down sampled size: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.69e-02 | test loss: 1.30e-02 | reg: 3.01e+00 : 100%|██| 20/20 [00:02<00:00,  9.53it/s]\n",
      "train loss: 1.43e-02 | test loss: 3.54e-02 | reg: 1.31e+03 : 100%|██| 50/50 [00:00<00:00, 79.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 0.9999997615814209\n",
      "r2 is 0.9999995231628418\n",
      "r2 is 0.999999463558197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.43e-02 | test loss: 3.54e-02 | reg: 1.31e+03 : 100%|██| 50/50 [00:00<00:00, 84.05it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.82*(-0.64*(0.14 - x_2)**3 + (0.21 - x_1)**4 + 0.25)**2 - 1.48\n",
      "sampled_index 1 signature  tensor([[ -0.0630, -21.5178, -10.6131,   5.3924, -52.3772,  30.1170]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "sampled_index 1 signature  tensor([[-1.7631e-02, -2.1176e+01, -1.1015e+01,  5.3337e+00, -5.8381e+01,\n",
      "          3.2079e+01]], grad_fn=<StackBackward0>)\n",
      "Number of vertices: 172974\n",
      "dataset full size: 359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.84e-02 | test loss: 2.86e-02 | reg: 4.04e+00 : 100%|██| 20/20 [00:02<00:00,  7.60it/s]\n",
      "train loss: 1.36e-02 | test loss: 2.90e-01 | reg: 2.27e+02 : 100%|██| 50/50 [00:01<00:00, 40.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 0.9846662282943726\n",
      "r2 is 0.9815137982368469\n",
      "r2 is 0.9883662462234497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.37e-02 | test loss: 2.36e-01 | reg: 2.27e+02 : 100%|██| 50/50 [00:00<00:00, 70.10it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-23.98*(-(0.74 - x_1)**4 - 0.84*(-x_2 - 0.67)**3 + 0.04)**2 - 0.02\n",
      "Number of vertices: 172974\n",
      "dataset down sampled size: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.76e-02 | test loss: 2.93e-02 | reg: 4.11e+00 : 100%|██| 20/20 [00:02<00:00,  9.80it/s]\n",
      "train loss: 1.36e-02 | test loss: 2.35e-01 | reg: 2.28e+02 : 100%|█| 50/50 [00:00<00:00, 120.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 1.0000004768371582\n",
      "r2 is 1.0000003576278687\n",
      "r2 is 0.9998894333839417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.36e-02 | test loss: 2.35e-01 | reg: 2.28e+02 : 100%|██| 50/50 [00:01<00:00, 30.99it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-23.99*(-(0.74 - x_1)**4 - 0.84*(-x_2 - 0.67)**3 + 0.04)**2 - 0.02\n",
      "sampled_index 2 signature  tensor([[ 9.0974e+01, -6.6355e-01, -4.3205e+02, -3.2503e+03, -6.3301e+00,\n",
      "         -1.9856e+03]], grad_fn=<StackBackward0>)\n",
      "sampled_index 2 signature  tensor([[ 9.1448e+01, -2.2884e-01, -4.3524e+02, -7.8497e+02, -1.9794e+00,\n",
      "         -1.7884e+03]], grad_fn=<StackBackward0>)\n",
      "Number of vertices: 172974\n",
      "dataset full size: 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 3.27e-02 | test loss: 3.11e-02 | reg: 3.41e+00 : 100%|██| 20/20 [00:01<00:00, 10.30it/s]\n",
      "train loss: 1.14e-02 | test loss: 1.69e-02 | reg: 3.63e+00 : 100%|██| 50/50 [00:01<00:00, 26.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 0.8571460843086243\n",
      "r2 is not very high, please double check if you are choosing the correct symbolic function.\n",
      "r2 is 0.9829180836677551\n",
      "r2 is 0.07512606680393219\n",
      "r2 is not very high, please double check if you are choosing the correct symbolic function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.31e-02 | test loss: 1.27e-02 | reg: 1.52e+03 : 100%|██| 50/50 [00:02<00:00, 19.95it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415921.44*(0.02 - x_1)**8 - 8.53\n",
      "Number of vertices: 172974\n",
      "dataset down sampled size: 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 3.17e-02 | test loss: 3.05e-02 | reg: 3.48e+00 : 100%|██| 20/20 [00:01<00:00, 10.66it/s]\n",
      "train loss: 1.29e-02 | test loss: 1.26e-02 | reg: 1.52e+03 : 100%|██| 50/50 [00:00<00:00, 72.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value at boundary.\n",
      "r2 is 0.38588064908981323\n",
      "r2 is not very high, please double check if you are choosing the correct symbolic function.\n",
      "Best value at boundary.\n",
      "r2 is 0.9997921586036682\n",
      "Best value at boundary.\n",
      "r2 is 0.9999637007713318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.30e-02 | test loss: 1.32e-02 | reg: 1.65e+03 : 100%|█| 50/50 [00:00<00:00, 102.14it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208318.38*((0.02 - x_1)**4 - 0.e-2)**2 - 14.5\n",
      "sampled_index 3 signature  tensor([[  6.9838,   4.3441,   3.3439, 758.0929,  16.4225, 477.3647]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "sampled_index 3 signature  tensor([[  8.4283,   8.9957,   8.3449, 770.1445,  34.7041, 829.9528]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "Number of vertices: 172974\n",
      "dataset full size: 332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.39e-02 | test loss: 2.45e-02 | reg: 3.20e+00 : 100%|██| 20/20 [00:02<00:00,  7.76it/s]\n",
      "train loss: 1.16e-03 | test loss: 2.02e-03 | reg: 4.16e+00 : 100%|██| 50/50 [00:01<00:00, 25.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 0.9656490683555603\n",
      "r2 is 0.4870888888835907\n",
      "r2 is not very high, please double check if you are choosing the correct symbolic function.\n",
      "Best value at boundary.\n",
      "r2 is 0.7955787777900696\n",
      "r2 is not very high, please double check if you are choosing the correct symbolic function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.47e-03 | test loss: 1.99e-03 | reg: 4.19e+00 : 100%|██| 50/50 [00:00<00:00, 70.86it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3558.61*(-(0.04 - x_2)**3 + 0.02*(0.54 - x_1)**4)**2\n",
      "Number of vertices: 172974\n",
      "dataset down sampled size: 266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.64e-02 | test loss: 1.62e-02 | reg: 3.26e+00 : 100%|██| 20/20 [00:02<00:00,  9.54it/s]\n",
      "train loss: 1.40e-03 | test loss: 1.94e-03 | reg: 4.03e+00 : 100%|██| 50/50 [00:00<00:00, 86.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value at boundary.\n",
      "r2 is 1.000000238418579\n",
      "Best value at boundary.\n",
      "r2 is 0.9993914365768433\n",
      "Best value at boundary.\n",
      "r2 is 0.8878657817840576\n",
      "r2 is not very high, please double check if you are choosing the correct symbolic function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.40e-03 | test loss: 1.90e-03 | reg: 4.16e+00 : 100%|██| 50/50 [00:00<00:00, 92.09it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2557.03*(-(0.04 - x_2)**3 + 0.02*(0.54 - x_1)**4)**2\n",
      "sampled_index 4 signature  tensor([[  0.6011,   0.1994,   9.7304,  -5.8379,   3.8581, -13.7009]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "sampled_index 4 signature  tensor([[  0.6315,   0.2105,   9.6439,  -5.1539,   3.5938, -13.7100]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "Number of vertices: 172974\n",
      "dataset full size: 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.94e-02 | test loss: 1.48e-02 | reg: 2.60e+00 : 100%|██| 20/20 [00:02<00:00,  9.78it/s]\n",
      "train loss: 1.21e-02 | test loss: 1.92e-02 | reg: 8.11e+01 : 100%|██| 50/50 [00:01<00:00, 32.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value at boundary.\n",
      "r2 is 0.6568630933761597\n",
      "r2 is not very high, please double check if you are choosing the correct symbolic function.\n",
      "r2 is 0.9242576956748962\n",
      "r2 is 0.3409081995487213\n",
      "r2 is not very high, please double check if you are choosing the correct symbolic function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.27e-02 | test loss: 1.33e-02 | reg: 9.11e+01 : 100%|██| 50/50 [00:00<00:00, 67.33it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-856432.6*(-0.44*(0.02 - x_1)**4 + (0.05 - x_2)**3)**2 - 0.02\n",
      "Number of vertices: 172974\n",
      "dataset down sampled size: 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.80e-02 | test loss: 1.33e-02 | reg: 2.45e+00 : 100%|██| 20/20 [00:01<00:00, 10.53it/s]\n",
      "train loss: 1.28e-02 | test loss: 1.46e-02 | reg: 9.22e+01 : 100%|██| 50/50 [00:00<00:00, 68.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value at boundary.\n",
      "r2 is 0.9980085492134094\n",
      "Best value at boundary.\n",
      "r2 is 0.9972281455993652\n",
      "r2 is 0.12490499019622803\n",
      "r2 is not very high, please double check if you are choosing the correct symbolic function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.28e-02 | test loss: 1.35e-02 | reg: 5.27e+01 : 100%|██| 50/50 [00:00<00:00, 65.37it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-385970.32*(-0.68*(0.02 - x_1)**4 + (0.06 - x_2)**3)**2 - 0.02\n",
      "sampled_index 5 signature  tensor([[ 2.9586e+01,  5.6860e+00,  1.2358e+01, -6.1141e+03,  5.6877e+02,\n",
      "          1.2314e+02]], grad_fn=<StackBackward0>)\n",
      "sampled_index 5 signature  tensor([[ 3.6898e+01,  5.6659e+00,  1.0058e+01, -6.2442e+03,  5.6689e+02,\n",
      "          8.5304e+02]], grad_fn=<StackBackward0>)\n",
      "Number of vertices: 172974\n",
      "dataset full size: 372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 3.03e-02 | test loss: 3.09e-02 | reg: 2.93e+00 : 100%|██| 20/20 [00:02<00:00,  6.72it/s]\n",
      "train loss: 6.28e-03 | test loss: 8.35e-03 | reg: 2.68e+00 : 100%|██| 50/50 [00:01<00:00, 29.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 0.9986988306045532\n",
      "Best value at boundary.\n",
      "r2 is 0.472756028175354\n",
      "r2 is not very high, please double check if you are choosing the correct symbolic function.\n",
      "Best value at boundary.\n",
      "r2 is 0.8497895002365112\n",
      "r2 is not very high, please double check if you are choosing the correct symbolic function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 7.35e-03 | test loss: 8.10e-03 | reg: 3.49e+00 : 100%|██| 50/50 [00:00<00:00, 57.46it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 - 25928.76*(0.01*(0.62 - x_1)**4 - (-x_2 - 0.e-2)**3)**2\n",
      "Number of vertices: 172974\n",
      "dataset down sampled size: 298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.99e-02 | test loss: 3.10e-02 | reg: 3.09e+00 : 100%|██| 20/20 [00:02<00:00,  8.99it/s]\n",
      "train loss: 7.19e-03 | test loss: 8.18e-03 | reg: 2.51e+00 : 100%|██| 50/50 [00:00<00:00, 50.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 1.0000005960464478\n",
      "Best value at boundary.\n",
      "r2 is 0.9573065638542175\n",
      "Best value at boundary.\n",
      "r2 is 0.9999556541442871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 7.24e-03 | test loss: 8.16e-03 | reg: 3.29e+00 : 100%|██| 50/50 [00:00<00:00, 59.00it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 - 11634.16*(0.01*(0.62 - x_1)**4 - (-x_2 - 0.02)**3)**2\n",
      "sampled_index 6 signature  tensor([[  -0.3971,   -1.5428,  -98.1364,   17.4545, -178.9933,  -31.5380]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "sampled_index 6 signature  tensor([[  -0.9147,   -2.0223,  -63.3516,   18.0572, -105.0968,  -46.0055]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "Number of vertices: 172974\n",
      "dataset full size: 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.34e-02 | test loss: 1.26e-02 | reg: 3.07e+00 : 100%|██| 20/20 [00:02<00:00,  9.25it/s]\n",
      "train loss: 1.63e-03 | test loss: 2.56e-03 | reg: 5.12e+00 : 100%|██| 50/50 [00:02<00:00, 21.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 0.9851526618003845\n",
      "r2 is 0.7706111073493958\n",
      "r2 is not very high, please double check if you are choosing the correct symbolic function.\n",
      "Best value at boundary.\n",
      "r2 is 0.9914263486862183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.28e-03 | test loss: 3.23e-03 | reg: 4.92e+00 : 100%|██| 50/50 [00:00<00:00, 53.07it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 - 20637.04*(0.12*(0.04 - x_2)**3 - (-x_1 - 0.08)**4)**2\n",
      "Number of vertices: 172974\n",
      "dataset down sampled size: 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 5.45e-03 | test loss: 5.09e-03 | reg: 3.24e+00 : 100%|██| 20/20 [00:02<00:00,  9.66it/s]\n",
      "train loss: 2.31e-03 | test loss: 3.21e-03 | reg: 3.79e+01 : 100%|██| 50/50 [00:01<00:00, 34.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 0.9999172687530518\n",
      "Best value at boundary.\n",
      "r2 is 0.9974643588066101\n",
      "Best value at boundary.\n",
      "r2 is 0.9999284744262695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.31e-03 | test loss: 3.22e-03 | reg: 3.80e+01 : 100%|█| 50/50 [00:00<00:00, 103.01it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6 - 106.71*(0.21*(0.04 - x_2)**3 - (-x_1 - 0.09)**4 + 0.18)**2\n",
      "sampled_index 7 signature  tensor([[  -1.2046,   -8.2415,   49.0697,   23.6165,  171.4696, -206.4889]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "sampled_index 7 signature  tensor([[  -0.9746,   -7.5478,   39.8110,   24.3118,  149.8528, -186.0753]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "Number of vertices: 172974\n",
      "dataset full size: 299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.42e-02 | test loss: 1.49e-02 | reg: 3.06e+00 : 100%|██| 20/20 [00:02<00:00,  8.73it/s]\n",
      "train loss: 3.69e-03 | test loss: 3.94e-03 | reg: 2.74e+00 : 100%|██| 50/50 [00:01<00:00, 29.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 0.9656178951263428\n",
      "r2 is 0.9675208330154419\n",
      "Best value at boundary.\n",
      "r2 is 0.7375677824020386\n",
      "r2 is not very high, please double check if you are choosing the correct symbolic function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 4.23e-03 | test loss: 5.46e-03 | reg: 3.64e+00 : 100%|██| 50/50 [00:00<00:00, 77.14it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.37*((0.25 - x_2)**3 + 0.25*(1 - 0.39*x_1)**4 - 0.27)**2\n",
      "Number of vertices: 172974\n",
      "dataset down sampled size: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 1.13e-02 | test loss: 1.23e-02 | reg: 3.25e+00 : 100%|██| 20/20 [00:02<00:00,  9.26it/s]\n",
      "train loss: 4.33e-03 | test loss: 5.62e-03 | reg: 2.71e+00 : 100%|██| 50/50 [00:00<00:00, 80.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 1.0000003576278687\n",
      "r2 is 1.0000003576278687\n",
      "Best value at boundary.\n",
      "r2 is 0.999991238117218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 4.33e-03 | test loss: 5.62e-03 | reg: 3.52e+00 : 100%|█| 50/50 [00:00<00:00, 128.64it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.31*((0.25 - x_2)**3 + 0.25*(1 - 0.4*x_1)**4 - 0.27)**2\n",
      "sampled_index 8 signature  tensor([[ -2.1923,  -1.0504, -19.6900,  -3.9416,  58.5136,  -2.7490]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "sampled_index 8 signature  tensor([[ -2.2952,  -1.1137, -20.9226,  -4.2731,  64.6986,  -2.8668]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "Number of vertices: 172974\n",
      "dataset full size: 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 7.41e-03 | test loss: 7.11e-03 | reg: 3.05e+00 : 100%|██| 20/20 [00:02<00:00,  7.34it/s]\n",
      "train loss: 2.23e-03 | test loss: 2.90e-03 | reg: 5.13e+00 : 100%|██| 50/50 [00:02<00:00, 22.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is 0.9971590638160706\n",
      "r2 is 0.9361170530319214\n",
      "Best value at boundary.\n",
      "r2 is 0.9865218997001648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.52e-03 | test loss: 3.02e-03 | reg: 5.99e+00 : 100%|██| 50/50 [00:00<00:00, 58.70it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47026.73*(0.03*(0.07 - x_2)**3 + (0.1 - x_1)**4)**2 - 0.02\n",
      "Number of vertices: 172974\n",
      "dataset down sampled size: 268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 6.73e-03 | test loss: 6.72e-03 | reg: 3.19e+00 : 100%|██| 20/20 [00:02<00:00,  9.17it/s]\n",
      "train loss: 2.56e-03 | test loss: 3.05e-03 | reg: 5.80e+00 : 100%|██| 50/50 [00:00<00:00, 68.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value at boundary.\n",
      "r2 is 0.9999982118606567\n",
      "r2 is 0.999930739402771\n",
      "Best value at boundary.\n",
      "r2 is 0.9967049360275269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss: 2.56e-03 | test loss: 3.05e-03 | reg: 5.86e+00 : 100%|██| 50/50 [00:00<00:00, 68.14it/s]\n",
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52001.56*(0.03*(0.07 - x_2)**3 + (0.1 - x_1)**4)**2 - 0.02\n",
      "sampled_index 9 signature  tensor([[  3.2499,   4.1720,   2.2970,  -7.1953,  45.0965, -41.2163]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "sampled_index 9 signature  tensor([[  3.2499,   4.2133,   1.9376, -11.6430,  44.0543, -50.2017]],\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "grid_range = 1.0\n",
    "ball_radius = 0.06 # for bunny worked good with 0.09 around 250 points neighbors\n",
    "lr = 1.0\n",
    "lamb = 100.0\n",
    "\n",
    "signatures_full_sampling = torch.zeros((len(sampled_indices), 6), dtype=torch.float32)\n",
    "signatures_down_sampled = torch.zeros((len(sampled_indices), 6), dtype=torch.float32)\n",
    "for i,sampled_index in enumerate(sampled_indices):\n",
    "    dataset_full_sample = create_dataset_from_mesh(mesh_path=mesh_path, sampled_index=sampled_index, show_sample=False, ball_radius=ball_radius, seed=i, down_sampling_ratio=1.0)\n",
    "    print(\"dataset full size:\" , len(dataset_full_sample[\"train_input\"]))\n",
    "    model_full_sampled = KAN(width=[2, 5, 1], grid=1, k=5, grid_eps=1.0, seed=0, grid_range=[-grid_range, grid_range], noise_scale=0.1, noise_scale_base=0.1, base_fun=torch.nn.SiLU(), learn_rotation_mat=False)\n",
    "    model_full_sampled.train(dataset_full_sample, opt=\"LBFGS\", steps=20, lr=lr, lamb=lamb, lamb_l1=1.0, lamb_entropy=1.0, lamb_coef=0.0, lamb_coefdiff=0.0, sglr_avoid=True, loss_fn=gaussian_weighted_mse)\n",
    "    model_full_sampled = model_full_sampled.prune(threshold=3e-3, mode='manual', active_neurons_id=[[0, 1], [0]])\n",
    "    model_full_sampled.train(dataset_full_sample, opt=\"LBFGS\", steps=50, lr=lr, sglr_avoid=True, loss_fn=gaussian_weighted_mse)\n",
    "     # manual mode\n",
    "    # if nan continue\n",
    "\n",
    "    # fix all\n",
    "    try:\n",
    "        model_full_sampled.fix_symbolic(0, 0, 0, 'x^4')\n",
    "        model_full_sampled.fix_symbolic(0, 1, 0, 'x^3')\n",
    "        model_full_sampled.fix_symbolic(1, 0, 0, 'x^2')\n",
    "    except:\n",
    "        print(\"nan encountered\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    model_full_sampled.train(dataset_full_sample, opt=\"LBFGS\", steps=50, lr=lr, sglr_avoid=True, lamb_coef=0.10, lamb_coefdiff=0.10, loss_fn=gaussian_weighted_mse)\n",
    "\n",
    "    print(model_full_sampled.symbolic_formula()[0][0])\n",
    "    x = torch.tensor([[0.0], [0.0]], requires_grad=True).T\n",
    "\n",
    "    signature_full = calculate_signature(model_full_sampled, x) # only calc sig in the origin\n",
    "\n",
    "\n",
    "    # down sampling\n",
    "\n",
    "    dataset_down_sampled = create_dataset_from_mesh(mesh_path=mesh_path, sampled_index=sampled_index, show_sample=False, ball_radius=ball_radius, seed=i, down_sampling_ratio=0.8)\n",
    "    print(\"dataset down sampled size:\" , len(dataset_down_sampled[\"train_input\"]))\n",
    "    model_down_sampled = KAN(width=[2, 5, 1], grid=1, k=5, grid_eps=1.0, seed=0, grid_range=[-grid_range, grid_range], noise_scale=0.1, noise_scale_base=0.1, base_fun=torch.nn.SiLU(), learn_rotation_mat=False)\n",
    "    model_down_sampled.train(dataset_down_sampled, opt=\"LBFGS\", steps=20, lr=lr, lamb=lamb, lamb_l1=1.0, lamb_entropy=1.0, lamb_coef=0.0, lamb_coefdiff=0.0, sglr_avoid=True, loss_fn=gaussian_weighted_mse)\n",
    "    model_down_sampled = model_full_sampled.prune(threshold=3e-3, mode='manual', active_neurons_id=[[0, 1], [0]])\n",
    "    model_down_sampled.train(dataset_down_sampled, opt=\"LBFGS\", steps=50, lr=lr, sglr_avoid=True, loss_fn=gaussian_weighted_mse)\n",
    "     # manual mode\n",
    "\n",
    "    # fix all\n",
    "    try:\n",
    "        model_down_sampled.fix_symbolic(0, 0, 0, 'x^4')\n",
    "        model_down_sampled.fix_symbolic(0, 1, 0, 'x^3')\n",
    "        model_down_sampled.fix_symbolic(1, 0, 0, 'x^2')\n",
    "    except:\n",
    "        print(\"nan encountered\")\n",
    "        continue\n",
    "\n",
    "    model_down_sampled.train(dataset_down_sampled, opt=\"LBFGS\", steps=50, lr=lr, sglr_avoid=True, lamb_coef=0.10, lamb_coefdiff=0.10, loss_fn=gaussian_weighted_mse)\n",
    "\n",
    "    print(model_down_sampled.symbolic_formula()[0][0])\n",
    "    x = torch.tensor([[0.0], [0.0]], requires_grad=True).T\n",
    "\n",
    "    signature_down_sampled = calculate_signature(model_down_sampled, x) # only calc sig in the origin\n",
    "    # check if signature_full or signature_down_sample is nan\n",
    "    if torch.isnan(signature_full).any(dim=1) or torch.isnan(signature_down_sampled).any(dim=1):\n",
    "        print(\"nan encountered\")\n",
    "        continue\n",
    "\n",
    "    print(\"sampled_index\", i, \"signature \", signature_full)\n",
    "    signatures_full_sampling[i,:] = signature_full\n",
    "    print(\"sampled_index\", i, \"signature \", signature_down_sampled)\n",
    "    signatures_down_sampled[i,:] = signature_down_sampled\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "indices_full_thrown = torch.isnan(signatures_full_sampling).any(dim=1)\n",
    "indices_full_thrown =torch.concatenate([indices_full_thrown, signatures_full_sampling.norm(dim=1) == 0])\n",
    "indices_down_sampled_thrown = torch.isnan(signatures_down_sampled).any(dim=1)\n",
    "indices_down_sampled_thrown = torch.concatenate([indices_down_sampled_thrown, signatures_down_sampled.norm(dim=1) == 0])\n",
    "\n",
    "# throw 0's\n",
    "signatures_full_sampling = signatures_full_sampling[signatures_full_sampling.norm(dim=1) != 0]\n",
    "signatures_down_sampled = signatures_down_sampled[signatures_down_sampled.norm(dim=1) != 0]\n",
    "# throw nan's\n",
    "signatures_full_sampling = signatures_full_sampling[~torch.isnan(signatures_full_sampling).any(dim=1)]\n",
    "signatures_down_sampled = signatures_down_sampled[~torch.isnan(signatures_down_sampled).any(dim=1)]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False])\n",
      "tensor([], dtype=torch.int64)\n",
      "torch.Size([20])\n",
      "tensor([], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "# indice_thrown indices, not logical\n",
    "# indices_full_thrown = torch.concatenate(indices_full_thrown)\n",
    "print(indices_full_thrown)\n",
    "print(torch.arange(len(indices_full_thrown))[indices_full_thrown])\n",
    "\n",
    "print(indices_down_sampled_thrown.shape)\n",
    "print(torch.arange(len(indices_down_sampled_thrown))[indices_down_sampled_thrown])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.5560e-02, -8.5463e-01, -3.4187e-01,  2.4566e-03, -9.6156e-01,\n",
      "         -2.1712e-01],\n",
      "        [-6.5545e-04, -4.5480e-01, -2.2331e-02,  7.7412e-04, -2.2929e-02,\n",
      "          1.4290e-02],\n",
      "        [ 9.4696e-01, -1.4025e-02, -9.0909e-01, -4.6661e-01, -2.7711e-03,\n",
      "         -9.4217e-01],\n",
      "        [ 7.2696e-02,  9.1817e-02,  7.0359e-03,  1.0883e-01,  7.1894e-03,\n",
      "          2.2651e-01],\n",
      "        [ 6.2572e-03,  4.2141e-03,  2.0474e-02, -8.3808e-04,  1.6890e-03,\n",
      "         -6.5010e-03],\n",
      "        [ 3.0796e-01,  1.2018e-01,  2.6004e-02, -8.7773e-01,  2.4899e-01,\n",
      "          5.8429e-02],\n",
      "        [-4.1333e-03, -3.2609e-02, -2.0649e-01,  2.5057e-03, -7.8359e-02,\n",
      "         -1.4965e-02],\n",
      "        [-1.2539e-02, -1.7419e-01,  1.0325e-01,  3.3904e-03,  7.5065e-02,\n",
      "         -9.7978e-02],\n",
      "        [-2.2819e-02, -2.2201e-02, -4.1430e-02, -5.6585e-04,  2.5616e-02,\n",
      "         -1.3044e-03],\n",
      "        [ 3.3829e-02,  8.8180e-02,  4.8332e-03, -1.0329e-03,  1.9742e-02,\n",
      "         -1.9557e-02]], grad_fn=<DivBackward0>)\n",
      "tensor([[-3.3742e-02, -8.6945e-01, -3.5843e-01,  2.6541e-03, -9.7073e-01,\n",
      "         -2.3619e-01],\n",
      "        [-1.7788e-04, -4.1301e-01, -2.3237e-02,  8.4123e-04, -2.3189e-02,\n",
      "          1.4447e-02],\n",
      "        [ 9.2262e-01, -4.4633e-03, -9.1812e-01, -1.2380e-01, -7.8625e-04,\n",
      "         -8.0542e-01],\n",
      "        [ 8.5033e-02,  1.7545e-01,  1.7603e-02,  1.2147e-01,  1.3785e-02,\n",
      "          3.7378e-01],\n",
      "        [ 6.3710e-03,  4.1057e-03,  2.0343e-02, -8.1287e-04,  1.4275e-03,\n",
      "         -6.1745e-03],\n",
      "        [ 3.7226e-01,  1.1051e-01,  2.1218e-02, -9.8483e-01,  2.2518e-01,\n",
      "          3.8418e-01],\n",
      "        [-9.2280e-03, -3.9443e-02, -1.3364e-01,  2.8480e-03, -4.1746e-02,\n",
      "         -2.0719e-02],\n",
      "        [-9.8330e-03, -1.4721e-01,  8.3979e-02,  3.8344e-03,  5.9523e-02,\n",
      "         -8.3802e-02],\n",
      "        [-2.3156e-02, -2.1721e-02, -4.4135e-02, -6.7394e-04,  2.5699e-02,\n",
      "         -1.2911e-03],\n",
      "        [ 3.2789e-02,  8.2176e-02,  4.0872e-03, -1.8363e-03,  1.7499e-02,\n",
      "         -2.2609e-02]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# normalize each entry to 1 in each of the 6 columns of the signature\n",
    "signatures_full_sampling_normalized = signatures_full_sampling / torch.norm(signatures_full_sampling, dim=0)\n",
    "signatures_down_sampled_normalized = signatures_down_sampled / torch.norm(signatures_down_sampled, dim=0)\n",
    "print(signatures_full_sampling_normalized)\n",
    "print(signatures_down_sampled_normalized)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.0736e-02, 1.1099e+00, 1.8050e+00, 1.5873e+00, 1.3573e+00, 1.9936e+00,\n",
      "         1.2622e+00, 1.3202e+00, 1.3431e+00, 1.4136e+00],\n",
      "        [1.1167e+00, 4.1809e-02, 1.5955e+00, 7.4250e-01, 4.6204e-01, 1.2768e+00,\n",
      "         4.3194e-01, 3.4990e-01, 4.3721e-01, 5.4145e-01],\n",
      "        [1.9111e+00, 1.7248e+00, 3.7012e-01, 1.9275e+00, 1.6858e+00, 1.8141e+00,\n",
      "         1.6085e+00, 1.6975e+00, 1.6711e+00, 1.6556e+00],\n",
      "        [1.5002e+00, 5.6447e-01, 1.6452e+00, 1.7074e-01, 2.8012e-01, 1.1657e+00,\n",
      "         3.4421e-01, 4.2417e-01, 2.9820e-01, 2.7587e-01],\n",
      "        [1.3809e+00, 4.2082e-01, 1.5408e+00, 4.4188e-01, 4.6625e-04, 1.1472e+00,\n",
      "         1.6733e-01, 1.9122e-01, 7.9472e-02, 8.6953e-02],\n",
      "        [1.8957e+00, 1.1089e+00, 1.6315e+00, 1.0982e+00, 9.6897e-01, 3.4986e-01,\n",
      "         1.0089e+00, 1.0046e+00, 9.7844e-01, 9.5131e-01],\n",
      "        [1.2528e+00, 4.2686e-01, 1.4188e+00, 5.2462e-01, 2.4365e-01, 1.2001e+00,\n",
      "         8.2183e-02, 3.4827e-01, 1.9459e-01, 2.6105e-01],\n",
      "        [1.3453e+00, 3.0900e-01, 1.5713e+00, 6.1592e-01, 2.2998e-01, 1.2114e+00,\n",
      "         3.0643e-01, 3.9363e-02, 2.3850e-01, 2.9434e-01],\n",
      "        [1.3661e+00, 3.9523e-01, 1.5249e+00, 4.5816e-01, 7.7259e-02, 1.1553e+00,\n",
      "         1.1794e-01, 1.9874e-01, 2.7715e-03, 1.2876e-01],\n",
      "        [1.4428e+00, 5.0610e-01, 1.5111e+00, 4.2445e-01, 9.2615e-02, 1.1351e+00,\n",
      "         2.0276e-01, 2.6327e-01, 1.3451e-01, 7.2581e-03]],\n",
      "       grad_fn=<CdistBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# measure correspondence according distance between signatures\n",
    "# before normalized each entry to 1\n",
    "\n",
    "distances = torch.cdist(signatures_full_sampling_normalized, signatures_down_sampled_normalized, p=2)\n",
    "print(distances)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0307, 0.0418, 0.3701, 0.1707, 0.0005, 0.3499, 0.0822, 0.0394, 0.0028,\n",
      "        0.0073], grad_fn=<MinBackward0>)\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# take minimum distance for each row and assign index which is the closest for each surface\n",
    "min_distances, min_indices = torch.min(distances, dim=1)\n",
    "print(min_distances)\n",
    "print(min_indices)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-3.5560e-02, -8.5463e-01, -3.4187e-01,  2.4566e-03, -9.6156e-01,\n         -2.1712e-01],\n        [-6.5545e-04, -4.5480e-01, -2.2331e-02,  7.7412e-04, -2.2929e-02,\n          1.4290e-02],\n        [ 9.4696e-01, -1.4025e-02, -9.0909e-01, -4.6661e-01, -2.7711e-03,\n         -9.4217e-01],\n        [ 7.2696e-02,  9.1817e-02,  7.0359e-03,  1.0883e-01,  7.1894e-03,\n          2.2651e-01],\n        [ 6.2572e-03,  4.2141e-03,  2.0474e-02, -8.3808e-04,  1.6890e-03,\n         -6.5010e-03],\n        [ 3.0796e-01,  1.2018e-01,  2.6004e-02, -8.7773e-01,  2.4899e-01,\n          5.8429e-02],\n        [-4.1333e-03, -3.2609e-02, -2.0649e-01,  2.5057e-03, -7.8359e-02,\n         -1.4965e-02],\n        [-1.2539e-02, -1.7419e-01,  1.0325e-01,  3.3904e-03,  7.5065e-02,\n         -9.7978e-02],\n        [-2.2819e-02, -2.2201e-02, -4.1430e-02, -5.6585e-04,  2.5616e-02,\n         -1.3044e-03],\n        [ 3.3829e-02,  8.8180e-02,  4.8332e-03, -1.0329e-03,  1.9742e-02,\n         -1.9557e-02]], grad_fn=<DivBackward0>)"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_full_sampling_normalized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-3.3742e-02, -8.6945e-01, -3.5843e-01,  2.6541e-03, -9.7073e-01,\n         -2.3619e-01],\n        [-1.7788e-04, -4.1301e-01, -2.3237e-02,  8.4123e-04, -2.3189e-02,\n          1.4447e-02],\n        [ 9.2262e-01, -4.4633e-03, -9.1812e-01, -1.2380e-01, -7.8625e-04,\n         -8.0542e-01],\n        [ 8.5033e-02,  1.7545e-01,  1.7603e-02,  1.2147e-01,  1.3785e-02,\n          3.7378e-01],\n        [ 6.3710e-03,  4.1057e-03,  2.0343e-02, -8.1287e-04,  1.4275e-03,\n         -6.1745e-03],\n        [ 3.7226e-01,  1.1051e-01,  2.1218e-02, -9.8483e-01,  2.2518e-01,\n          3.8418e-01],\n        [-9.2280e-03, -3.9443e-02, -1.3364e-01,  2.8480e-03, -4.1746e-02,\n         -2.0719e-02],\n        [-9.8330e-03, -1.4721e-01,  8.3979e-02,  3.8344e-03,  5.9523e-02,\n         -8.3802e-02],\n        [-2.3156e-02, -2.1721e-02, -4.4135e-02, -6.7394e-04,  2.5699e-02,\n         -1.2911e-03],\n        [ 3.2789e-02,  8.2176e-02,  4.0872e-03, -1.8363e-03,  1.7499e-02,\n         -2.2609e-02]], grad_fn=<DivBackward0>)"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_down_sampled_normalized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.1099, grad_fn=<LinalgVectorNormBackward0>)"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(signatures_full_sampling_normalized[0] - signatures_down_sampled_normalized[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(10)"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum all the min_indices whice equal their index, for example if 0 is in 0 index, add 1 to the counter\n",
    "torch.sum(min_indices == torch.arange(len(min_indices)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0 min_distances tensor([0.0018, 0.0005, 0.0243, 0.0123, 0.0001, 0.0643, 0.0040, 0.0027, 0.0003,\n",
      "        0.0010], grad_fn=<MinBackward0>) min_indices tensor([0, 1, 2, 3, 4, 5, 1, 7, 8, 9])\n",
      "i 0 sum tensor(9)\n",
      "i 1 min_distances tensor([0.0149, 0.0418, 0.0262, 0.0411, 0.0002, 0.0650, 0.0085, 0.0271, 0.0006,\n",
      "        0.0061], grad_fn=<MinBackward0>) min_indices tensor([0, 1, 2, 9, 4, 5, 6, 7, 8, 9])\n",
      "i 1 sum tensor(9)\n",
      "i 2 min_distances tensor([0.0223, 0.0418, 0.0277, 0.0412, 0.0002, 0.0652, 0.0733, 0.0333, 0.0028,\n",
      "        0.0061], grad_fn=<MinBackward0>) min_indices tensor([0, 1, 2, 9, 4, 5, 6, 7, 8, 9])\n",
      "i 2 sum tensor(9)\n",
      "i 3 min_distances tensor([2.2292e-02, 4.1808e-02, 3.4392e-01, 8.6129e-02, 2.0600e-04, 1.2538e-01,\n",
      "        7.3351e-02, 3.3270e-02, 2.7702e-03, 6.1912e-03],\n",
      "       grad_fn=<MinBackward0>) min_indices tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "i 3 sum tensor(10)\n",
      "i 4 min_distances tensor([2.4104e-02, 4.1809e-02, 3.4393e-01, 8.6381e-02, 3.3290e-04, 1.2763e-01,\n",
      "        8.1981e-02, 3.6722e-02, 2.7714e-03, 6.5851e-03],\n",
      "       grad_fn=<MinBackward0>) min_indices tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "i 4 sum tensor(10)\n",
      "i 5 min_distances tensor([0.0307, 0.0418, 0.3701, 0.1707, 0.0005, 0.3499, 0.0822, 0.0394, 0.0028,\n",
      "        0.0073], grad_fn=<MinBackward0>) min_indices tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "i 5 sum tensor(10)\n"
     ]
    }
   ],
   "source": [
    "# test of distances only using the first entry of the signature, then the first and second, then the first, second and third and so on til the fifth\n",
    "for i in range(6):\n",
    "    distances = torch.cdist(signatures_full_sampling_normalized[:, :i+1], signatures_down_sampled_normalized[:, :i+1], p=2)\n",
    "    min_distances, min_indices = torch.min(distances, dim=1)\n",
    "    print(\"i\", i, \"min_distances\", min_distances, \"min_indices\", min_indices)\n",
    "    print(\"i\", i, \"sum\", torch.sum(min_indices == torch.arange(len(min_indices))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0 min_distances tensor([0.0018, 0.0005, 0.0243, 0.0123, 0.0001, 0.0643, 0.0040, 0.0027, 0.0003,\n",
      "        0.0010], grad_fn=<MinBackward0>) min_indices tensor([0, 1, 2, 3, 4, 5, 1, 7, 8, 9])\n",
      "i 0 sum tensor(9)\n",
      "i 1 min_distances tensor([0.0148, 0.0418, 0.0077, 0.0096, 0.0001, 0.0097, 0.0068, 0.0270, 0.0005,\n",
      "        0.0060], grad_fn=<MinBackward0>) min_indices tensor([0, 1, 8, 9, 4, 5, 6, 7, 8, 9])\n",
      "i 1 sum tensor(8)\n",
      "i 2 min_distances tensor([0.0166, 0.0009, 0.0090, 0.0029, 0.0001, 0.0048, 0.0729, 0.0193, 0.0027,\n",
      "        0.0007], grad_fn=<MinBackward0>) min_indices tensor([0, 1, 2, 9, 4, 5, 6, 7, 8, 9])\n",
      "i 2 sum tensor(9)\n",
      "i 3 min_distances tensor([1.9743e-04, 6.7105e-05, 3.4281e-01, 1.2636e-02, 2.5212e-05, 1.0710e-01,\n",
      "        1.4832e-04, 4.4409e-04, 1.0809e-04, 2.2008e-04],\n",
      "       grad_fn=<MinBackward0>) min_indices tensor([0, 1, 2, 3, 4, 5, 0, 7, 8, 4])\n",
      "i 3 sum tensor(8)\n",
      "i 4 min_distances tensor([9.1698e-03, 2.6008e-04, 1.9849e-03, 5.7619e-03, 2.6151e-04, 2.3816e-02,\n",
      "        3.6613e-02, 1.5542e-02, 8.3182e-05, 2.2433e-03],\n",
      "       grad_fn=<MinBackward0>) min_indices tensor([0, 1, 2, 4, 4, 5, 6, 7, 8, 9])\n",
      "i 4 sum tensor(9)\n",
      "i 5 min_distances tensor([1.9072e-02, 1.5696e-04, 1.3675e-01, 1.4728e-01, 3.2645e-04, 4.3982e-02,\n",
      "        5.7547e-03, 1.4176e-02, 1.3251e-05, 1.1625e-03],\n",
      "       grad_fn=<MinBackward0>) min_indices tensor([0, 1, 2, 3, 4, 1, 6, 7, 8, 6])\n",
      "i 5 sum tensor(8)\n"
     ]
    }
   ],
   "source": [
    "# i want to check per entry which one is the closest and then do a major vote\n",
    "# for example surface i first entry is closest to surface j and second is closest to k and so on then i new_sig = [j,k,..,..,...] in the end we majority vote which closest, if j appear the most in i new sig then i is closest to j\n",
    "for i in range(6):\n",
    "    distances = torch.cdist(signatures_full_sampling_normalized[:, i:i+1], signatures_down_sampled_normalized[:, i:i+1], p=2)\n",
    "    min_distances, min_indices = torch.min(distances, dim=1)\n",
    "    print(\"i\", i, \"min_distances\", min_distances, \"min_indices\", min_indices)\n",
    "    print(\"i\", i, \"sum\", torch.sum(min_indices == torch.arange(len(min_indices))))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6])\n",
      "torch.Size([10, 6])\n"
     ]
    }
   ],
   "source": [
    "## check correspondence using cosine similarity\n",
    "cosine_similarity = torch.nn.CosineSimilarity(dim=1)\n",
    "print(signatures_full_sampling.shape)\n",
    "print(signatures_down_sampled.shape)\n",
    "# cosine_sim = cosine_similarity(signatures_full_sampling, signatures_down_sampled)\n",
    "# print(cosine_sim)\n",
    "# correspondence = torch.argmax(cosine_sim, dim=1)\n",
    "# print(correspondence)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "torch.save(signatures_full_sampling_normalized, mesh_path+ 'signatures_full_sampling_200_surfaces.pt')\n",
    "torch.save(signatures_down_sampled, mesh_path+'signatures_down_sampled_200_surfaces.pt')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.2.2'"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0 cosine_sim tensor([ 1.0000,  0.7284,  0.1952, -0.1744, -0.0815, -0.1225,  0.8821, -0.4558,\n",
      "        -0.8950, -0.4866], grad_fn=<SumBackward1>)\n",
      "i 0 correspondence tensor(0)\n",
      "i 1 cosine_sim tensor([ 0.7039,  0.9992, -0.4085,  0.3660, -0.6297, -0.0918,  0.5715, -0.8549,\n",
      "        -0.7306, -0.8999], grad_fn=<SumBackward1>)\n",
      "i 1 correspondence tensor(1)\n",
      "i 2 cosine_sim tensor([ 0.1119, -0.2789,  0.8201, -0.9564,  0.5801,  0.7665,  0.1195,  0.2915,\n",
      "         0.1070,  0.5240], grad_fn=<SumBackward1>)\n",
      "i 2 correspondence tensor(3)\n",
      "i 3 cosine_sim tensor([-0.1240,  0.2873, -0.8077,  0.9661, -0.6451, -0.7613, -0.0862, -0.3109,\n",
      "        -0.0595, -0.5252], grad_fn=<SumBackward1>)\n",
      "i 3 correspondence tensor(3)\n",
      "i 4 cosine_sim tensor([-0.0878, -0.6246,  0.6824, -0.7582,  0.9993,  0.2349, -0.2066,  0.7599,\n",
      "         0.0874,  0.7645], grad_fn=<SumBackward1>)\n",
      "i 4 correspondence tensor(4)\n",
      "i 5 cosine_sim tensor([-0.1014, -0.1425,  0.3719, -0.6592,  0.2909,  0.9934, -0.2174, -0.0574,\n",
      "         0.1485,  0.2159], grad_fn=<SumBackward1>)\n",
      "i 5 correspondence tensor(5)\n",
      "i 6 cosine_sim tensor([ 0.9068,  0.7236,  0.2065, -0.0842, -0.3360, -0.1817,  0.9771, -0.4838,\n",
      "        -0.6722, -0.4753], grad_fn=<SumBackward1>)\n",
      "i 6 correspondence tensor(6)\n",
      "i 7 cosine_sim tensor([-0.4637, -0.8679,  0.5993, -0.4733,  0.7734, -0.1304, -0.3085,  0.9997,\n",
      "         0.5653,  0.9496], grad_fn=<SumBackward1>)\n",
      "i 7 correspondence tensor(7)\n",
      "i 8 cosine_sim tensor([-0.8901, -0.7472,  0.1310, -0.0496,  0.0692,  0.1406, -0.5906,  0.5572,\n",
      "         0.9999,  0.6432], grad_fn=<SumBackward1>)\n",
      "i 8 correspondence tensor(8)\n",
      "i 9 cosine_sim tensor([-0.5768, -0.9367,  0.6348, -0.5443,  0.7131,  0.0908, -0.3829,  0.9509,\n",
      "         0.7131,  0.9925], grad_fn=<SumBackward1>)\n",
      "i 9 correspondence tensor(9)\n",
      "[tensor(0), tensor(1), tensor(3), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9)]\n",
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "#calculate cosine similarity between the two signatures, i want to\n",
    "cosine_similarity = torch.nn.CosineSimilarity(dim=1)\n",
    "cosine_similarity_mapping = []\n",
    "for i in range(len(signatures_full_sampling)):\n",
    "    cosine_sim = cosine_similarity(signatures_full_sampling[i], signatures_down_sampled)\n",
    "    print(\"i\", i, \"cosine_sim\", cosine_sim)\n",
    "    correspondence = torch.argmax(torch.abs(cosine_sim))\n",
    "    print(\"i\", i, \"correspondence\", correspondence)\n",
    "    cosine_similarity_mapping.append(correspondence)\n",
    "\n",
    "print(cosine_similarity_mapping)\n",
    "# sum all the cosine_similarity_mapping whice equal their index, for example if 0 is in 0 index, add 1 to the counter\n",
    "print(torch.sum(torch.tensor(cosine_similarity_mapping) == torch.arange(len(cosine_similarity_mapping))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 9.0974e+01, -6.6355e-01, -4.3205e+02, -3.2503e+03, -6.3301e+00,\n        -1.9856e+03], grad_fn=<SelectBackward0>)"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_full_sampling[2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-1.7631e-02, -2.1176e+01, -1.1015e+01,  5.3337e+00, -5.8381e+01,\n         3.2079e+01], grad_fn=<SelectBackward0>)"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_down_sampled[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
