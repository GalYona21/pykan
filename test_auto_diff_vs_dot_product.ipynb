{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from kan import *\n",
    "from my_functions import calculate_signature, format_signature, calculate_signature_just_autodiff\n",
    "\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1000, 2]), torch.Size([1000, 1]))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f = lambda x: x[:,[0]]**2 - x[:,[1]]**2\n",
    "theta = np.pi / 6  # 30 degrees in radians\n",
    "\n",
    "rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                            [np.sin(theta),  np.cos(theta)]])\n",
    "\n",
    "f = lambda x: (x @ rotation_matrix)[:,[0]]**2 - (x @ rotation_matrix)[:,[1]]**2\n",
    "\n",
    "N = 1000\n",
    "N_sqrt = int(N**0.5)\n",
    "dataset = create_dataset(f, n_var=2, train_num=N, test_num=N, seed=0)\n",
    "dataset['train_input'].shape, dataset['train_label'].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                         | 0/20 [7:17:57<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m model(dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_input\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# model.plot(beta=100)\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mLBFGS\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlamb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlamb_l1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlamb_entropy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2.\u001B[39;49m\u001B[43m)\u001B[49m;\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# model.plot()\u001B[39;00m\n\u001B[1;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39mprune()\n",
      "File \u001B[0;32m~/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:921\u001B[0m, in \u001B[0;36mKAN.train\u001B[0;34m(self, dataset, opt, steps, log, lamb, lamb_l1, lamb_entropy, lamb_coef, lamb_coefdiff, update_grid, grid_update_num, loss_fn, lr, stop_grid_update_step, batch, small_mag_threshold, small_reg_factor, metrics, sglr_avoid, save_fig, in_vars, out_vars, beta, save_fig_freq, img_folder, device)\u001B[0m\n\u001B[1;32m    917\u001B[0m         os\u001B[38;5;241m.\u001B[39mmakedirs(img_folder)\n\u001B[1;32m    919\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m pbar:\n\u001B[0;32m--> 921\u001B[0m     train_id \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice(dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_input\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], batch_size, replace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    922\u001B[0m     test_id \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice(dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_input\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], batch_size_test, replace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    924\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _ \u001B[38;5;241m%\u001B[39m grid_update_freq \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m _ \u001B[38;5;241m<\u001B[39m stop_grid_update_step \u001B[38;5;129;01mand\u001B[39;00m update_grid:\n",
      "File \u001B[0;32m~/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/venv/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    380\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    381\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    382\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    383\u001B[0m             )\n\u001B[0;32m--> 385\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    388\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/LBFGS.py:433\u001B[0m, in \u001B[0;36mLBFGS.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    430\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mobj_func\u001B[39m(x, t, d):\n\u001B[1;32m    431\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_directional_evaluate(closure, x, t, d)\n\u001B[0;32m--> 433\u001B[0m     loss, flat_grad, t, ls_func_evals \u001B[38;5;241m=\u001B[39m \u001B[43m_strong_wolfe\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    434\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobj_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_init\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflat_grad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgtd\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    435\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_add_grad(t, d)\n\u001B[1;32m    436\u001B[0m opt_cond \u001B[38;5;241m=\u001B[39m flat_grad\u001B[38;5;241m.\u001B[39mabs()\u001B[38;5;241m.\u001B[39mmax() \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m tolerance_grad\n",
      "File \u001B[0;32m~/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/LBFGS.py:50\u001B[0m, in \u001B[0;36m_strong_wolfe\u001B[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001B[0m\n\u001B[1;32m     48\u001B[0m g \u001B[38;5;241m=\u001B[39m g\u001B[38;5;241m.\u001B[39mclone(memory_format\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mcontiguous_format)\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# evaluate objective and gradient using initial step\u001B[39;00m\n\u001B[0;32m---> 50\u001B[0m f_new, g_new \u001B[38;5;241m=\u001B[39m \u001B[43mobj_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     51\u001B[0m ls_func_evals \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     52\u001B[0m gtd_new \u001B[38;5;241m=\u001B[39m g_new\u001B[38;5;241m.\u001B[39mdot(d)\n",
      "File \u001B[0;32m~/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/LBFGS.py:431\u001B[0m, in \u001B[0;36mLBFGS.step.<locals>.obj_func\u001B[0;34m(x, t, d)\u001B[0m\n\u001B[1;32m    430\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mobj_func\u001B[39m(x, t, d):\n\u001B[0;32m--> 431\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_directional_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/LBFGS.py:283\u001B[0m, in \u001B[0;36mLBFGS._directional_evaluate\u001B[0;34m(self, closure, x, t, d)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_directional_evaluate\u001B[39m(\u001B[38;5;28mself\u001B[39m, closure, x, t, d):\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_add_grad(t, d)\n\u001B[0;32m--> 283\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(\u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    284\u001B[0m     flat_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gather_flat_grad()\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_param(x)\n",
      "File \u001B[0;32m~/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:902\u001B[0m, in \u001B[0;36mclosure\u001B[0;34m()\u001B[0m\n\u001B[1;32m    900\u001B[0m id_ \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mwhere(torch\u001B[38;5;241m.\u001B[39misnan(torch\u001B[38;5;241m.\u001B[39msum(pred, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    901\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m loss_fn_given:\n\u001B[0;32m--> 902\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m loss_fn(pred[id_], dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_label\u001B[39m\u001B[38;5;124m'\u001B[39m][train_id][id_]\u001B[38;5;241m.\u001B[39mto(device), x)\n\u001B[1;32m    903\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    904\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m loss_fn(pred[id_], dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_label\u001B[39m\u001B[38;5;124m'\u001B[39m][train_id][id_]\u001B[38;5;241m.\u001B[39mto(device))\n",
      "File \u001B[0;32m~/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:863\u001B[0m, in \u001B[0;36mKAN.train.<locals>.<lambda>\u001B[0;34m(x, y)\u001B[0m\n\u001B[1;32m    861\u001B[0m loss_fn_given \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    862\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m loss_fn \u001B[38;5;241m==\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 863\u001B[0m     loss_fn \u001B[38;5;241m=\u001B[39m loss_fn_eval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m x, y: torch\u001B[38;5;241m.\u001B[39mmean((x \u001B[38;5;241m-\u001B[39m y) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    864\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    865\u001B[0m     loss_fn \u001B[38;5;241m=\u001B[39m loss_fn_eval \u001B[38;5;241m=\u001B[39m loss_fn\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:915\u001B[0m, in \u001B[0;36mPyDBFrame.trace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    912\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m back \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    913\u001B[0m     \u001B[38;5;66;03m# if we're in a return, we want it to appear to the user in the previous frame!\u001B[39;00m\n\u001B[1;32m    914\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_suspend(thread, step_cmd)\n\u001B[0;32m--> 915\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    916\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    917\u001B[0m     \u001B[38;5;66;03m# in jython we may not have a back frame\u001B[39;00m\n\u001B[1;32m    918\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclear_run_state(info)\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:144\u001B[0m, in \u001B[0;36mPyDBFrame.do_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1175\u001B[0m         time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = KAN(width=[2,5,1], grid=3, k=5, grid_eps=1.0, seed=0, grid_range=[-1.0,1.0], learn_rotation_mat=True)\n",
    "model(dataset['train_input'])\n",
    "# model.plot(beta=100)\n",
    "model.train(dataset, opt=\"LBFGS\", steps=20, lamb=0.0, lamb_l1=1, lamb_entropy=2.);\n",
    "# model.plot()\n",
    "model.prune()\n",
    "# model.plot(mask=True)\n",
    "model(dataset['train_input'])\n",
    "model.train(dataset, opt=\"LBFGS\", steps=50);\n",
    "mode = \"auto\" # \"manual\"\n",
    "\n",
    "if mode == \"manual\":\n",
    "    # manual mode\n",
    "    model.fix_symbolic(0,0,0,'sin');\n",
    "    model.fix_symbolic(0,1,0,'x^2');\n",
    "    model.fix_symbolic(1,0,0,'exp');\n",
    "elif mode == \"auto\":\n",
    "    # automatic mode\n",
    "    # lib = ['x','x^2','x^3','x^4','exp','log','sqrt','tanh','sin','abs']\n",
    "    lib = ['x','x^2','x^3','x^4']\n",
    "    model.auto_symbolic(lib=lib)\n",
    "\n",
    "model.train(dataset, opt=\"LBFGS\", steps=50)\n",
    "print(model.symbolic_formula()[0][0])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gal.yona/Documents/MSc/Thesis/ImplicitNeuralSurfaces/forked_pykan/pykan/kan/KAN.py:344: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  self.acts_scale_std.append(torch.std(postacts, dim=0))\n"
     ]
    },
    {
     "data": {
      "text/plain": "'H: 0.0079, K: -3.9943, H_1: -0.0018, H_2: 0.0051, K_1: 0.0003, K_2: -0.0138'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[0.0], [0.0]], requires_grad=True).T\n",
    "signature = calculate_signature(model, x)\n",
    "format_signature(signature)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'H: 0.0079, K: -3.9943, H_1: -0.0009, H_2: 0.0053, K_1: 0.0067, K_2: -0.0121'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature_autodiff = calculate_signature_just_autodiff(model, x)\n",
    "format_signature(signature_autodiff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'H: -0.2460, K: -3.9006, H_1: 1.9603, H_2: -1.4703, K_1: 4.1356, K_2: 3.6560'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'H: -0.2460, K: -3.9006, H_1: 1.9603, H_2: -1.4703, K_1: 4.1356, K_2: 3.6560'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([0.2733], requires_grad=True)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.alpha"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
